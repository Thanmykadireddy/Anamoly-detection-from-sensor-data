{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c03bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anomaly Detection from Sensor Data - Celebal AnaVerse_B\n",
    "\n",
    "# Importing essential libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932feca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Machine learning tools and metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "import lightgbm as lgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd00c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Deep learning library\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e38fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Load Full Dataset ===\n",
    "# Function to reduce memory usage by downcasting numerical columns\n",
    "def reduce_memory(df):\n",
    "    for col in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "        df[col] = pd.to_numeric(df[col], downcast='float')\n",
    "    return df\n",
    "\n",
    "print(\"ðŸ”„ Loading datasets...\")\n",
    "# Load training and test datasets\n",
    "train_df = pd.read_csv(\"/content/drive/MyDrive/new/train.csv\", low_memory=False)\n",
    "test_df = pd.read_csv(\"/content/drive/MyDrive/new/test.csv\", low_memory=False)\n",
    "sample_submission = pd.read_csv(\"/content/drive/MyDrive/new/sample-submission.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dce1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply memory optimization\n",
    "train_df = reduce_memory(train_df)\n",
    "test_df = reduce_memory(test_df)\n",
    "print(\"âœ… Data loaded.\")\n",
    "\n",
    "# === Preprocessing ===\n",
    "# Drop columns that are completely empty\n",
    "train_df.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "# Fill missing values with column means\n",
    "train_df.fillna(train_df.mean(numeric_only=True), inplace=True)\n",
    "test_df.fillna(test_df.mean(numeric_only=True), inplace=True)\n",
    "\n",
    "# Identify and drop datetime columns\n",
    "datetime_cols = []\n",
    "for col in train_df.columns:\n",
    "    if train_df[col].dtype == 'object':\n",
    "        try:\n",
    "            pd.to_datetime(train_df[col])\n",
    "            datetime_cols.append(col)\n",
    "        except:\n",
    "            continue\n",
    "train_df.drop(columns=datetime_cols, inplace=True, errors='ignore')\n",
    "test_df.drop(columns=datetime_cols, inplace=True, errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e1f373",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# === Feature Engineering ===\n",
    "# Visualizing correlations between features using a heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(train_df.corr(numeric_only=True), cmap='coolwarm', annot=False)\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65db9745",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Keep only the columns common between train and test (excluding target)\n",
    "common_columns = [col for col in train_df.columns if col in test_df.columns and col != \"target\"]\n",
    "X = train_df[common_columns]\n",
    "y = train_df[\"target\"]\n",
    "X_test = test_df[common_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64390685",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Scaling ===\n",
    "# Standardizing the feature values\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcbd523",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Train/Validation Split ===\n",
    "# Splitting data for validation purposes\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2aafa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Logistic Regression ===\n",
    "log_model = LogisticRegression(max_iter=200)\n",
    "log_model.fit(X_train, y_train)\n",
    "log_pred = log_model.predict(X_val)\n",
    "print(\"\\nðŸ“Š Logistic Regression:\")\n",
    "print(classification_report(y_val, log_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90fb392",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Support Vector Machine ===\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_pred = svm_model.predict(X_val)\n",
    "print(\"\\nðŸ“Š Support Vector Machine:\")\n",
    "print(classification_report(y_val, svm_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8019d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Random Forest ===\n",
    "# Using random forest classifier for robust ensemble learning\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred = rf_model.predict(X_val)\n",
    "print(\"\\nðŸ“Š Random Forest:\")\n",
    "print(classification_report(y_val, rf_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796b1741",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === LightGBM ===\n",
    "# Gradient boosting model tuned with learning rate\n",
    "lgb_model = lgb.LGBMClassifier(n_estimators=100, learning_rate=0.05, random_state=42, n_jobs=-1)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "lgb_pred = lgb_model.predict(X_val)\n",
    "print(\"\\nðŸ“Š LightGBM:\")\n",
    "print(classification_report(y_val, lgb_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d6d1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Neural Network ===\n",
    "# Basic MLP neural network with 2 hidden layers\n",
    "nn_model = Sequential()\n",
    "nn_model.add(Dense(64, input_dim=X.shape[1], activation='relu'))\n",
    "nn_model.add(Dense(32, activation='relu'))\n",
    "nn_model.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d95fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compile and fit the model\n",
    "nn_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "nn_model.fit(X_train, y_train, epochs=5, batch_size=64, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cec499",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predict on validation set\n",
    "nn_pred = nn_model.predict(X_val).ravel()\n",
    "nn_pred_class = (nn_pred > 0.5).astype(int)\n",
    "print(\"\\nðŸ“Š Neural Network:\")\n",
    "print(classification_report(y_val, nn_pred_class))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf7c0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Final Model for Submission ===\n",
    "# Retrain LightGBM on full data and predict test labels\n",
    "print(\"\\nðŸ“ˆ Retraining on full dataset with LightGBM...\")\n",
    "lgb_model.fit(X, y)\n",
    "test_preds = lgb_model.predict(X_test)\n",
    "\n",
    "# Prepare the submission file\n",
    "submission = pd.DataFrame({\n",
    "    'ID': sample_submission['ID'],\n",
    "    'target': test_preds\n",
    "})\n",
    "submission.to_csv(\"my_submission.csv\", index=False)\n",
    "print(\"\\nâœ… Final submission saved as 'my_submission.csv' with\", len(submission), \"rows.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
